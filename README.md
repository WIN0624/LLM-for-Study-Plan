<<<<<<< Updated upstream
# LLM-for-Study-Plan

* **<u>Framwork</u>**：Torch

* **<u>Library</u>**

  * Unsloth
  * Huggingface-Transformers
  * SFTTrainer

* **<u>ComputationResources</u>**

  * HPC；Autodl

* **<u>Components</u>**

  * DatasetPreprocessing => DataSetDownload
    * 3 Task
  * Model => Freezing Most, Reset some 
    * ModelChoice：Which model? Which layer's weights to be trained?
    * FinetuningTricks：Only hyperpara or add Layers?
    * Loss：What loss？
    * TrainingWay：Multi-object/Multi-task
  * Metrics => Precison, Recall

* **<u>Technical</u>** 

  * Joint Learning?

* **<u>Difficulty</u>**

  * computation resources
  * training speed

* **<u>Application</u>**

  * For presentation： different scenario => based on chatbot

    * P0
      * solve math problems
      * generate a study plan (grade, weakeness domain)
    * P1
      * input error set (answer question + analyze weakness + generate plan)

  * For report

    * compare with baseline

      * Math QA => public dataset

      * Concept Extracting => self-customed dataset + model-labeld dataset (train/test)

        > How many data are required

* **<u>STEPS|MileStones</u>**

  * **Model Construction**

    * Find public github repo + adapt to our tasks(data processing)

      > REF: [Github](https://github.com/togethercomputer/finetuning)
      >
      > [GPT-4 Finetuned](https://github.com/liutiedong/goat)
      >
      > Math-Finetuning Github with metrics
      >
      > Finetuning Lllama3 8B Github

    * Llam3 3B/8B + Lora

      > 8B: 14GB, 16bit  
      >
      > 3B: 4bit
      > [Tutorial](https://github.com/amitlevy/finetune_llama_3_own_data/blob/master/llama3_8b_finetune_own_data.ipynb)

    * Finetune on Math dataset

    * Hyperpara: lr

    * Resources

      > VastAi, 1 4090 =>  1 24GB, 0.35

    * **Checkpoint**

      * **Accuaray Metrics for this two, accuracy/solveRate**

        > Rule-base extraction
        >
        > ChatGpt extraction

      * **Training Framwork**

  * **PromptEngineering**

    * target: find best prompt to solve question

      > Metrics |  How do people measures prompt improvements
      >
      > refer COT, still accuracy
      >
      > refer ROSCOE => evaluate reasoning
      >
      > refer Confidence of Hallucination => study plan (confidence higher than baseline)

    * only prompt

    * prompt + sft

    * **Checkpoint**

      * Inference Framwork
      * Reasoning Metrics

  * **PresentationWay**

    * Quantize + Deploy on phone
    * Comparison: Quantized Version

  * **Serving**

    * Ollama 
=======
## ✨ Integrated Framework with Customized LLMs Metrics

This tutorial are **beginner friendly**! This repository aims to help users customize their own LLMs for domain-specific tasks at a low cost. By using this framework, you will not only obtain a fine-tuned LLMs for your task but also gain a well-customized metric/rubric integrating human feedbacks to evaluate responses generated by the LLM. 

With this rubric you can advance your works or even merge it into your promts to guide LLM-based labeling for your dataset.

<img src="https://cdn.jsdelivr.net/gh/WIN0624/Picgo@main/img/202412181558724.png" alt="image-20241218155844694" style="zoom:85%;" />

**【Quick Navigation】**

* Without a domain-specific dataset, start with the **`METRICS DEFINITION`** section

* With a domain-specific datasets, start with the **`Finetuning`** section
* Check out this [Tutorial for Customizing Personalized Learning Plan Evaluation Metrics Notebook] for quick start

## ⭐ Key Features

* Supports 4bit and 16bit QLoRA / LoRA finetuning via [Unsloth](https://github.com/unslothai/unsloth) 
* Introduces prompting techniques to customize evaluation metrics for generalized real-world problems
* Plug-and-Play prompt framework
* On-Device deployment with an interface for exporting models and saving to GGFU
* Reusable evaluation metrics for generating and evaluating personlized educational resources

## 💾 Installation Instructions

### Requirements Installation

### Domain-specific LLM Finetuning

### Metrics Customization



## 🔗 Links and Resources

| Type                                  | Links                                                        |
| :------------------------------------ | :----------------------------------------------------------- |
| 📚 **Documentation**                   | [Read Our Docs](https://docs.unsloth.ai/)                    |
| 💾 **Installation**                    | [unsloth/README.md](https://github.com/unslothai/unsloth/tree/main#-installation-instructions) |
| 🥇 **Experiment Results**              | [Performance Tables](https://github.com/unslothai/unsloth/tree/main#-performance-benchmarking) |
| 🌐 Tutorial on Personalized Study Plan |                                                              |



## 🥇 Experiment Results
>>>>>>> Stashed changes
